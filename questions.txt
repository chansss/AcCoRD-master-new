就是我们的这些模拟器到底模拟了是什么
还有是咱们从list改为pool 他的容量是怎么算的 我再这几个文档里没有找到描述
1触发层和转发层它特指的是 在我们的project中如何体现2 就是我们一直跑的都是默认，需要跑其他的模拟 3.他那个种子的信息在哪里查看呢 4 还有是咱们从list改为pool 他的容量是怎么算的 5. 10的 567次方的分子数量是如何修改的？
用 SoA 重构微观扩散内核 Structure-of-Arrays（SoA） 形式（例如 x[], y[], z[], needUpdate[]），把分子属性放到连续数组中，改为批量循环更新，从而：

减少内存间接访问与 cache miss；

为批处理与向量化创造条件；

在遍历主导的合成基准中体现出明显上限收益。 这些结果都是怎么跑出来的  我们采用 guarded integration（受保护接入）：先检查 region/配置是否满足 SoA 快路径的前提条件 这个条件具体是什么
触发层（Trigger）

定义“什么时候触发一次中继动作”，支持：

绝对阈值触发（可选上升沿，避免持续高于阈值导致重复触发）；

增量阈值触发（当观测相对上一次基准累计增长到一定幅度才触发）。 2.2 转发层（Relay / AF Mapping）

定义“触发后释放多少”，将观测值映射为释放强度：10
5
/
10
6
/
10
7
10
5
/10
6
/10
7
 到底代表什么：每次释放的分子数、系统内同时存在的分子数、还是 某个窗口累计释放量？三者完全不同。

你们如何保证 SoA 快路径与 legacy 路径在“正确性”上等价？是 bitwise 一致还是统计一致？给出明确标准与证据。

guarded entry 的 兼容性检查具体检查哪些条件？逐条列出，并解释每条的必要性。

当配置不兼容回退时，SoA 池里已有分子如何处理？会不会 重复更新/漏更新？

真实扩散端到端仅 5–6% 提升：你们的 profiling 证据是什么？瓶颈到底在 RNG、验证、边界处理还是调度？

SoA 结构是否真的支持 SIMD/批处理？你们做了还是没做？没做的原因是什么？

Dependent Actor 的“立即触发”在离散事件仿真里是什么意思：同一事件内执行还是插入新事件？时间戳如何定义？

增量阈值里 
𝑝
𝑟
𝑒
𝑣
𝐶
𝑜
𝑢
𝑛
𝑡
prevCount 何时更新（每次观测后/每次触发后/每个符号后）？不同策略会导致完全不同的触发频率。

AF 映射得到的 strength 是整数还是实数？如何取整？取整会不会引入偏差？

dependentRelayMode=2 允许负增量，物理意义是什么？clamp 会不会系统性抹掉弱信号？

参数 gain/bias/min/max 的单位/含义是什么？如何与观测计数匹配（数量级、尺度）？

多 actor 同时触发时，执行顺序是否确定？是否依赖容器遍历顺序而引入非确定性？

你们 baseline 是否真的是“原版 AcCoRD v1.0”？编译器、优化级别、宏定义完全一致吗？

SoA 引入后内存占用变化多少？10^7 分子时是否触发分页/内存带宽瓶颈？

你们的实验能否复现：配置文件、seed、Monte Carlo 次数、统计指标定义是否全部写清？

1. 研究问题与贡献边界

你们的核心研究问题是什么：性能工程、功能扩展、还是两者兼顾？主目标如何排序？

“更快”的指标是什么：wall-clock、每 step 时间、每分子更新时间、还是吞吐（molecules/s）？

“正确性”的定义是什么：轨迹一致、统计一致、还是通信层指标一致？

你们贡献 1/2/3 的边界如何划分？guarded entry 属于性能还是正确性？

你们的改动对 AcCoRD 其他模块（mesoscopic、reactions、surfaces）有没有副作用？

2. 实验设置与 
10
5
/
10
6
/
10
7
10
5
/10
6
/10
7
 的“带入方式”（结果强相关）

10
5
/
10
6
/
10
7
10
5
/10
6
/10
7
 是 每次 emission 的释放量还是 系统内初始分子数？如果两者都有，分别在哪张图？

如果是每次释放量：是通过哪个参数设置（modStrength / strength）？随机释放是否关闭？

如果是系统内分子数：是如何初始化的（t=0 注入？预生成池？逐步释放累积到该规模？）

这三个数量级下，仿真时长/step 数是否相同？如果不同，如何保证可比性？

是否控制了分子类型数量、region 数量、边界类型一致？否则 N 增大同时也改变了其他复杂度。

统计结果是单次运行还是多次 Monte Carlo 平均？方差/置信区间是否报告？

输出指标是什么：运行时间、加速比、观测曲线、误码率、到达计数？每个指标如何计算？

触发/AF 实验里，obsValue 的窗口是多长？窗口长度改变会显著改变 depCount 的尺度。你们是否固定？

seed 如何设置？old/new 是否同 seed？若 RNG 调用顺序改变，如何解释不一致？

3. SoA 数据结构与内存语义（贡献 1 的细节漏洞）

SoA 到底包含哪些数组字段？仅 x/y/z/needUpdate 还是还包括 moleculeType、regionId、valid、state？

needUpdate 的语义是什么：本 step 更新标记？边界处理后复检标记？由谁置位、何时清零？

SoA 池的粒度是什么：每 region 一个池？全局池？每分子类型一个池？为什么这样设计？

分子增删如何实现：swap-and-pop、free-list、还是 compact？

删除/交换会改变分子顺序：这会不会影响 RNG 调用顺序、触发顺序、统计输出顺序？

外部是否存储分子索引/引用？如果 swap 导致索引变化，如何避免悬挂引用？

SoA 是否有容量预分配策略？10^7 分子是否反复扩容造成额外开销？

SoA 的内存对齐/缓存行利用是否考虑？有没有定量证据（L1/L2 miss、带宽）？

SoA 是否引入额外拷贝（AoS→SoA 或 SoA→AoS）？何时发生？成本是否计入？

4. guarded entry + fallback 的定义是否充分（贡献 2）

“配置兼容性检查”具体检查哪些条件？请逐条列出（region geometry、boundary type、reactions、surfaces、molecule type、meso/micro coupling 等）。

哪些条件是“物理正确性必须”，哪些只是“性能不划算”？你们有没有混用？

guard 判断是在 diffuseMolecules 的哪个层级做（每 step 一次、每 region 一次、每分子类型一次）？

兼容性判断是否可能误判？有没有针对每条 guard 条件设计反例测试？

fallback 后，SoA 中的分子是否迁回 legacy？还是继续留在 SoA 但不更新？如何避免重复/漏更新？

是否存在“部分兼容”的情况（某些 region 兼容、某些不兼容）？策略是局部启用还是全局禁用？

guard 的开销多大？当大多数配置不兼容时，guard 开销会不会抵消收益？

“向后兼容”具体指哪些接口/配置文件格式/输出格式不变？有无破坏性更改？

5. 正确性验证（你们最容易写得“泛泛而谈”的部分）

你们验证了哪些 invariant：分子总数守恒、边界吸收率、反射概率、到达统计、时间序列一致性？

old vs new 的对照是否在相同 seed、相同配置、相同输出指标下进行？

如果无法 bitwise 一致，你们用什么统计检验（均值误差阈值、KS test、置信区间重叠）？

SoA 与 legacy 在边界处理上是否完全同逻辑？尤其是复杂边界/region 接触处。

事件调度是否完全一致？是否引入新的事件类型或改变事件插入时机？

输出文件格式/日志是否一致？是否有任何隐藏的“调试输出”影响性能/结果？

10^7 分子下是否出现数值异常（NaN、越界）？如何检测与处理？

6. 性能评估与归因（为什么快/为什么不快）

合成基准具体测什么？如何保证它只测 traversal，不被 RNG、验证、I/O 混入？

真实扩散端到端测的场景配置是什么（region 数、边界、反应、分子类型、时间步）？

加速比的定义是什么：T_old/T_new？是否包含初始化/输出/统计？

profiling 用了什么工具/方法？给出热点函数占比：RNG、validate、boundary、heap 调度、内存分配。

端到端只有 5–6%：你们能否量化“RNG 主导”占比（例如 60%+）来支持结论？

SoA 的收益主要来自减少 cache miss 还是减少分配/指针追逐？有没有硬件计数器证据？

不同 N（10^5→10^7）下加速比是否变化？如果变化，原因是什么（缓存溢出、带宽饱和）？

你们有没有测量内存占用与带宽？10^7 分子是否触发分页导致性能异常？

编译器优化级别（-O2/-O3）是否一致？是否启用 AVX/SSE？这会显著影响结论。

7. RNG（随机数）与“统计正确性”风险点

SoA 之后 RNG 调用顺序是否改变？如果改变，如何确保统计意义正确？

RNG 生成的是每分子每步一个随机向量吗？还是按维度生成？调用次数如何计数？

是否考虑批量 RNG（vectorized RNG）？没做的原因是工程成本还是正确性担忧？

若未来做 SIMD RNG，如何保证可复现（同 seed 下跨平台一致性）？

RNG 的开销占比多少？是否是你们下一步优化的首选？为什么？

8. Dependent Actor：触发时机、因果性、并发一致性（贡献 3 的追问区）

passive observation 的事件在调度队列里是什么类型？触发逻辑插在该事件的哪个阶段？

“立即触发”是同一事件内直接调用释放，还是插入一个新 release event？

若插入新事件：其时间戳是 t、t+ε 还是下一个 slot？这一点决定因果关系与可复现性。

如果同一时刻有多个 passive actors 更新，触发检查顺序是否固定？是否依赖容器遍历顺序？

是否可能出现链式触发（A→B→C）在同一时刻连锁执行？你们是否限制触发深度？

是否可能出现循环依赖触发（A 依赖 B，B 依赖 A）？如何检测与防止死循环？

触发是否受 startTime、numMaxAction、bMaxAction 等限制？这些限制与 triggerMode 的交互是否定义清楚？

actor 依赖的分子类型如何指定？是否支持多个 molecule types 的联合触发？

9. Trigger Layer：定义细节（最容易“文中没说清”）

depCount 的定义是什么：当前瞬时计数、窗口内累积计数、还是到 t 的累计？

prevCount 的定义是什么：上次观测值、上次触发时的观测值、还是上个 symbol 的观测值？

mode=1（增量阈值）里 prevCount 在何时更新？触发后更新还是每次观测后更新？请写出伪代码级别定义。

mode=0 + rising-edge 使用的 prevCount 是哪个时刻的？若观测频率高，会不会漏触发/多触发？

触发检查是每次 passive observation 都检查？还是按某个间隔检查？

“累计增长触发”是否会在噪声波动下频繁触发？你们是否考虑去抖（debounce）或最小间隔？

10. Relay/AF Mapping：strength 的物理含义与数值处理

strength 表示“释放分子数”还是“释放速率/概率/浓度”？必须明确。

strength 若是实数，最终释放时如何处理：round/floor/随机取整？这会影响统计。

gain/bias 的取值范围如何选？有没有依据（对齐文献、对齐物理量级）？

minStrength/maxStrength 的默认值是什么？实验中具体值是什么？

clamp 的策略会引入非线性饱和，是否会偏离 AF 线性假设？你们是否讨论饱和区间比例？

dependentRelayMode=0 调用原始 newRelease：newRelease 与 strength 的接口如何一致？旧逻辑是否绕过了强度映射？

dependentRelayMode=2 用增量 obsValue：负值代表什么？clamp 到 0 后是否等价于“静默中继”？

是否允许 bias<0 或 gain<0？若允许，物理解释是什么？若不允许，文中应写约束。

11. 与文献对齐与可复现实验声明

你们的 AF 触发/映射与哪篇经典 AF/多跳 MC 模型一一对应？参数如何映射？

你们是否复现过某篇论文的一条关键曲线（趋势一致即可）来证明模型对齐？

你们的 observation window、slotInterval 与文献中的采样时刻是否一致？

是否解释“为什么选择线性映射”？是否支持阈值型/非线性映射作为扩展？

你们的实验中继链路是几跳？是否演示端到端随 hop 增加的衰减/放大行为？

12. 工程交付与复跑（老师想“我怎么验证你说的”）

你们提供的 old/new 可执行文件如何保证同环境公平对比？

README 是否写清：运行命令、配置文件、seed、输出路径、统计脚本？

版本控制里是否能清晰看到你们对 v1.0 的 diff？关键改动是否集中在少数文件？

你们是否提供最小可复现案例（MRE）：一个 region、一个 passive、一个 dependent actor，跑出触发效果？

你们的新增参数是否有默认值？旧配置文件不加新字段是否还能跑？

日志/调试开关是否关闭？I/O 是否会影响性能测量？

13. 局限性与下一步（老师常问“你知道你没做什么吗”）

SoA 当前覆盖哪些配置？不支持的配置有哪些（多 region、多分子类型、反应、表面）？为什么难？

如果加入反应/表面，你们的 SoA 需要加哪些字段与流程？guard 条件如何扩展？

RNG 是主瓶颈：下一步你们计划怎么做（批量 RNG、向量 RNG、缓存 RNG）？对正确性的影响如何控制？

是否考虑多线程/MPI？哪些模块适合并行，哪些会受事件队列串行限制？

Dependent Actor 是否支持更复杂策略（DF、非线性、阈值映射、多分子类型联合编码）？尤其是我们的的判断条件，比如eligibility trigger  capacity 退回 这些必须得在论文中明确 以及